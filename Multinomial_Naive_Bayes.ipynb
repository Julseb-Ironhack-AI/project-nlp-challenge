{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df78ccd",
   "metadata": {},
   "source": [
    "# Project NLP Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c0d0f",
   "metadata": {},
   "source": [
    "Explain what the project is for, and quickly how we are going to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24491ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0\\tdonald trump sends out embarrassing new year‚s eve message; this is disturbing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\tdrunk bragging trump staffer started russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\tsheriff david clarke becomes an internet jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\ttrump is so obsessed he even has obama‚s na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\tpope francis just called out donald trump d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0\\tracist alabama cops brutalize black boy whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0\\tdonald trump sends out embarrassing new year‚s eve message; this is disturbing\n",
       "0  0\\tdrunk bragging trump staffer started russia...                               \n",
       "1  0\\tsheriff david clarke becomes an internet jo...                               \n",
       "2  0\\ttrump is so obsessed he even has obama‚s na...                               \n",
       "3  0\\tpope francis just called out donald trump d...                               \n",
       "4  0\\tracist alabama cops brutalize black boy whi...                               "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dfset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/training_data_lowercase.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed249b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>trump is so obsessed he even has obama‚s name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>racist alabama cops brutalize black boy while ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title\n",
       "0      0  drunk bragging trump staffer started russian c...\n",
       "1      0  sheriff david clarke becomes an internet joke ...\n",
       "2      0  trump is so obsessed he even has obama‚s name ...\n",
       "3      0  pope francis just called out donald trump duri...\n",
       "4      0  racist alabama cops brutalize black boy while ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the two columns to have label and title\n",
    "df[['label', 'title']] = df[df.columns[0]].str.split('\\t', n=1, expand=True)\n",
    "\n",
    "# Convert label to integer\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Reorder columns if needed\n",
    "df = df[['label', 'title']]\n",
    "\n",
    "# Show the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d2ca207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27320, 2)\n",
      "(6831, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split dfset\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb966856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\"]\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[110:150])\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "print(snowball.stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56fcc6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   preprocessed_text  \\\n",
      "0  drunk bragging trump staffer started russian c...   \n",
      "1  sheriff david clarke becomes an internet joke ...   \n",
      "2  trump is so obsessed he even has obamas name c...   \n",
      "3  pope francis just called out donald trump duri...   \n",
      "4  racist alabama cops brutalize black boy while ...   \n",
      "\n",
      "                                        no_stopwords  \n",
      "0  drunk bragging trump staffer started russian c...  \n",
      "1  sheriff david clarke becomes internet joke thr...  \n",
      "2  trump obsessed even obamas name coded website ...  \n",
      "3  pope francis called donald trump christmas speech  \n",
      "4  racist alabama cops brutalize black boy handcu...  \n",
      "                                       preprocessed_text  \\\n",
      "1847   paul ryan makes perfect argument for medicare ...   \n",
      "3457   evan mcmullin issues dire warning for all amer...   \n",
      "23069       iraq says will stay clear of usiran tensions   \n",
      "29487  turkeys erdogan says will take jerusalem resol...   \n",
      "6624   bill maher insults trumps supposed masculinity...   \n",
      "\n",
      "                                            no_stopwords  \n",
      "1847   paul ryan makes perfect argument medicare dumb...  \n",
      "3457   evan mcmullin issues dire warning americans tr...  \n",
      "23069               iraq says stay clear usiran tensions  \n",
      "29487  turkeys erdogan says take jerusalem resolution...  \n",
      "6624   bill maher insults trumps supposed masculinity...  \n",
      "                                       preprocessed_text  \\\n",
      "10145  univ of ga professor allows students to choose...   \n",
      "26342  clinton says trump is most divisive candidate ...   \n",
      "22172   ivanka trump becomes unpaid white house employee   \n",
      "365    bill maher turns gops states rights nonsense o...   \n",
      "13323  she grew up believing blacks could only suppor...   \n",
      "\n",
      "                                            no_stopwords  \n",
      "10145  univ ga professor allows students choose grade...  \n",
      "26342    clinton says trump divisive candidate lifetimes  \n",
      "22172   ivanka trump becomes unpaid white house employee  \n",
      "365    bill maher turns gops states rights nonsense h...  \n",
      "13323  grew believing blacks could support democratsu...  \n"
     ]
    }
   ],
   "source": [
    "# Remove special characters and others\n",
    "import re\n",
    "\n",
    "# Remove special characters\n",
    "def remove_special_characters(text):\n",
    "\treturn re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "df[\"text_nospecial\"] = df[\"title\"].apply(remove_special_characters)\n",
    "df_train[\"text_nospecial\"] = df_train[\"title\"].apply(remove_special_characters)\n",
    "df_test[\"text_nospecial\"] = df_test[\"title\"].apply(remove_special_characters)\n",
    "\n",
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    "\treturn re.sub(r'\\d+', '', text)\n",
    "\n",
    "df['text_nonum'] = df['text_nospecial'].apply(remove_numbers)\n",
    "df_train['text_nonum'] = df_train['text_nospecial'].apply(remove_numbers)\n",
    "df_test['text_nonum'] = df_test['text_nospecial'].apply(remove_numbers)\n",
    "\n",
    "# Remove all single characters\n",
    "def remove_single_characters(text):\n",
    "\treturn re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "\n",
    "df['text_nosingle'] = df['text_nonum'].apply(remove_single_characters)\n",
    "df_train['text_nosingle'] = df_train['text_nonum'].apply(remove_single_characters)\n",
    "df_test['text_nosingle'] = df_test['text_nonum'].apply(remove_single_characters)\n",
    "\n",
    "# Remove single characters from the start\n",
    "def remove_single_characters_start(text):\n",
    "\treturn re.sub(r'^[a-zA-Z]\\s+', '', text)\n",
    "\n",
    "df['text_nosingle_start'] = df['text_nosingle'].apply(remove_single_characters_start)\n",
    "df_train['text_nosingle_start'] = df_train['text_nosingle'].apply(remove_single_characters_start)\n",
    "df_test['text_nosingle_start'] = df_test['text_nosingle'].apply(remove_single_characters_start)\n",
    "\n",
    "# Substitute multiple spaces with single space\n",
    "def substitute_multiple_spaces(text):\n",
    "\treturn re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "df['text_nospaces'] = df['text_nosingle_start'].apply(substitute_multiple_spaces)\n",
    "df_train['text_nospaces'] = df_train['text_nosingle_start'].apply(substitute_multiple_spaces)\n",
    "df_test['text_nospaces'] = df_test['text_nosingle_start'].apply(substitute_multiple_spaces)\n",
    "\n",
    "# Remove prefixed 'b'\n",
    "def remove_prefixed_b(text):\n",
    "\treturn re.sub(r'^b\\s+', '', text)\n",
    "\n",
    "df['text_noprefixb'] = df['text_nospaces'].apply(remove_prefixed_b)\n",
    "df_train['text_noprefixb'] = df_train['text_nospaces'].apply(remove_prefixed_b)\n",
    "df_test['text_noprefixb'] = df_test['text_nospaces'].apply(remove_prefixed_b)\n",
    "\n",
    "# Convert to Lowercase\n",
    "df['preprocessed_text'] = df['text_noprefixb'].str.lower()\n",
    "df_train['preprocessed_text'] = df_train['text_noprefixb'].str.lower()\n",
    "df_test['preprocessed_text'] = df_test['text_noprefixb'].str.lower()\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "\treturn ' '.join([word for word in text.split() if word not in stop_words])\n",
    "df['no_stopwords'] = df['preprocessed_text'].apply(remove_stopwords)\n",
    "df_train['no_stopwords'] = df_train['preprocessed_text'].apply(remove_stopwords)\n",
    "df_test['no_stopwords'] = df_test['preprocessed_text'].apply(remove_stopwords)\n",
    "\n",
    "print(df[['preprocessed_text', 'no_stopwords']].head())\n",
    "print(df_train[['preprocessed_text', 'no_stopwords']].head())\n",
    "print(df_test[['preprocessed_text', 'no_stopwords']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7006f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        no_stopwords  \\\n",
      "0  drunk bragging trump staffer started russian c...   \n",
      "1  sheriff david clarke becomes internet joke thr...   \n",
      "2  trump obsessed even obamas name coded website ...   \n",
      "3  pope francis called donald trump christmas speech   \n",
      "4  racist alabama cops brutalize black boy handcu...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [drunk, bragging, trump, staffer, started, rus...   \n",
      "1  [sheriff, david, clarke, becomes, internet, jo...   \n",
      "2  [trump, obsessed, even, obamas, name, coded, w...   \n",
      "3  [pope, francis, called, donald, trump, christm...   \n",
      "4  [racist, alabama, cops, brutalize, black, boy,...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  [drunk, brag, trump, staffer, start, russian, ...  \n",
      "1  [sheriff, david, clark, becom, internet, joke,...  \n",
      "2  [trump, obsess, even, obama, name, code, websi...  \n",
      "3  [pope, franci, call, donald, trump, christma, ...  \n",
      "4  [racist, alabama, cop, brutal, black, boy, han...  \n"
     ]
    }
   ],
   "source": [
    "# Ensure 'no_stopwords' column exists before proceeding\n",
    "if 'no_stopwords' in df.columns:\n",
    "\t# Break sentences into words\n",
    "\tdf['tokens'] = df['no_stopwords'].apply(lambda x: x.split())\n",
    "\tdf_train['tokens'] = df_train['no_stopwords'].apply(lambda x: x.split())\n",
    "\tdf_test['tokens'] = df_test['no_stopwords'].apply(lambda x: x.split())\n",
    "\n",
    "\t# Use lemmatization (actually stemming here)\n",
    "\tdf['lemmatized'] = df['tokens'].apply(lambda tokens: [snowball.stem(token) for token in tokens])\n",
    "\tdf_train['lemmatized'] = df_train['tokens'].apply(lambda tokens: [snowball.stem(token) for token in tokens])\n",
    "\tdf_test['lemmatized'] = df_test['tokens'].apply(lambda tokens: [snowball.stem(token) for token in tokens])\n",
    "\n",
    "\t# Print the result\n",
    "\tprint(df[['no_stopwords', 'tokens', 'lemmatized']].head())\n",
    "else:\n",
    "\tprint(\"Column 'no_stopwords' not found. Please run the cell that creates it first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6731c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in fake news: [('trump', 5729), ('video', 4415), ('obama', 1407), ('hillari', 1158), ('presid', 681), ('clinton', 658), ('republican', 640), ('get', 633), ('break', 597), ('tweet', 593)]\n",
      "Top 10 words in real news: [('trump', 4144), ('us', 2840), ('say', 1962), ('hous', 1163), ('senat', 936), ('republican', 777), ('white', 655), ('russia', 606), ('new', 537), ('bill', 528)]\n"
     ]
    }
   ],
   "source": [
    "# Bag of words\n",
    "from collections import Counter\n",
    "\n",
    "# Your code\n",
    "# Flatten lemmatized tokens for real and fake news\n",
    "fake_news = [word for tokens in df_train[df_train['label'] == 0]['lemmatized'] for word in tokens]\n",
    "real_news = [word for tokens in df_train[df_train['label'] == 1]['lemmatized'] for word in tokens]\n",
    "\n",
    "# Count and get top 10\n",
    "top_fake = Counter(fake_news).most_common(10)\n",
    "top_real = Counter(real_news).most_common(10)\n",
    "\n",
    "print(\"Top 10 words in fake news:\", top_fake)\n",
    "print(\"Top 10 words in real news:\", top_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4d284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Bag of Words (CountVectorizer) X_train: (27320, 20204)\n",
      "Shape of Bag of Words (CountVectorizer) X_test: (6831, 20204)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Your code\n",
    "# Use the preprocessed text (without stopwords) for vectorization\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(df_train['no_stopwords'])\n",
    "X_test_bow = vectorizer.transform(df_test['no_stopwords'])\n",
    "\n",
    "print(\"Shape of Bag of Words (CountVectorizer) X_train:\", X_train_bow.shape)\n",
    "print(\"Shape of Bag of Words (CountVectorizer) X_test:\", X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91ee5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (majority class): 0.5146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict using a simple baseline: majority class in training set\n",
    "majority_class = df_train['label'].mode()[0]\n",
    "y_pred_baseline = [majority_class] * len(df_test)\n",
    "y_true = df_test['label']\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred_baseline)\n",
    "print(f\"Baseline accuracy (majority class): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e87f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.9281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_bow, df_train['label'])\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = clf.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_nb = accuracy_score(y_true, y_pred_nb)\n",
    "print(f\"Naive Bayes accuracy: {accuracy_nb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f075188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.93      0.93      0.93      3515\n",
      "        Real       0.93      0.93      0.93      3316\n",
      "\n",
      "    accuracy                           0.93      6831\n",
      "   macro avg       0.93      0.93      0.93      6831\n",
      "weighted avg       0.93      0.93      0.93      6831\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate precision, recall, f1-score, and support for Naive Bayes predictions\n",
    "report = classification_report(y_true, y_pred_nb, target_names=['Fake', 'Real'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2abb238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2\\tcopycat muslim terrorist arrested with assault weapons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2\\twow! chicago protester caught on camera adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\tgermany's fdp look to fill schaeuble's big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2\\tmi school sends welcome back packet warning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2\\tu.n. seeks 'massive' aid boost amid rohingy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2\\tdid oprah just leave ‚nasty‚ hillary wishin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2\\tcopycat muslim terrorist arrested with assault weapons\n",
       "0  2\\twow! chicago protester caught on camera adm...       \n",
       "1  2\\tgermany's fdp look to fill schaeuble's big ...       \n",
       "2  2\\tmi school sends welcome back packet warning...       \n",
       "3  2\\tu.n. seeks 'massive' aid boost amid rohingy...       \n",
       "4  2\\tdid oprah just leave ‚nasty‚ hillary wishin...       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 2 to 0 or 1 in the file testing_data_lowercase_nolabels\n",
    "# Add headers to dataset\n",
    "# Separate the values in dataset\n",
    "dt = pd.read_csv(\"./dataset/testing_data_lowercase_nolabels.csv\", encoding=\"utf-8-sig\")\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "833069d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>wow! chicago protester caught on camera admits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>germany's fdp look to fill schaeuble's big shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mi school sends welcome back packet warning ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>u.n. seeks 'massive' aid boost amid rohingya '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>did oprah just leave ‚nasty‚ hillary wishing s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title\n",
       "0      2  wow! chicago protester caught on camera admits...\n",
       "1      2   germany's fdp look to fill schaeuble's big shoes\n",
       "2      2  mi school sends welcome back packet warning ki...\n",
       "3      2  u.n. seeks 'massive' aid boost amid rohingya '...\n",
       "4      2  did oprah just leave ‚nasty‚ hillary wishing s..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, add headers from dataset and separate the values\n",
    "dt[['label', 'title']] = dt[dt.columns[0]].str.split('\\t', n=1, expand=True)\n",
    "\n",
    "# Remove BOM and whitespace, then convert label to integer\n",
    "dt['label'] = dt['label'].str.replace('\\ufeff', '', regex=False).str.strip().astype(int)\n",
    "\n",
    "# Reorder columns if needed\n",
    "dt = dt[['label', 'title']]\n",
    "\n",
    "# Show the result\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "290885ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title  \\\n",
      "0      0  wow! chicago protester caught on camera admits...   \n",
      "1      1   germany's fdp look to fill schaeuble's big shoes   \n",
      "2      0  mi school sends welcome back packet warning ki...   \n",
      "3      1  u.n. seeks 'massive' aid boost amid rohingya '...   \n",
      "4      0  did oprah just leave ‚nasty‚ hillary wishing s...   \n",
      "\n",
      "                                      text_nospecial  \\\n",
      "0  wow chicago protester caught on camera admits ...   \n",
      "1     germanys fdp look to fill schaeubles big shoes   \n",
      "2  mi school sends welcome back packet warning ki...   \n",
      "3  un seeks massive aid boost amid rohingya emerg...   \n",
      "4  did oprah just leave nasty hillary wishing she...   \n",
      "\n",
      "                                          text_nonum  \\\n",
      "0  wow chicago protester caught on camera admits ...   \n",
      "1     germanys fdp look to fill schaeubles big shoes   \n",
      "2  mi school sends welcome back packet warning ki...   \n",
      "3  un seeks massive aid boost amid rohingya emerg...   \n",
      "4  did oprah just leave nasty hillary wishing she...   \n",
      "\n",
      "                                       text_nosingle  \\\n",
      "0  wow chicago protester caught on camera admits ...   \n",
      "1     germanys fdp look to fill schaeubles big shoes   \n",
      "2  mi school sends welcome back packet warning ki...   \n",
      "3  un seeks massive aid boost amid rohingya emerg...   \n",
      "4  did oprah just leave nasty hillary wishing she...   \n",
      "\n",
      "                                 text_nosingle_start  \\\n",
      "0  wow chicago protester caught on camera admits ...   \n",
      "1     germanys fdp look to fill schaeubles big shoes   \n",
      "2  mi school sends welcome back packet warning ki...   \n",
      "3  un seeks massive aid boost amid rohingya emerg...   \n",
      "4  did oprah just leave nasty hillary wishing she...   \n",
      "\n",
      "                                       text_nospaces  \\\n",
      "0  wow chicago protester caught on camera admits ...   \n",
      "1     germanys fdp look to fill schaeubles big shoes   \n",
      "2  mi school sends welcome back packet warning ki...   \n",
      "3  un seeks massive aid boost amid rohingya emerg...   \n",
      "4  did oprah just leave nasty hillary wishing she...   \n",
      "\n",
      "                                      text_noprefixb  \\\n",
      "0  wow chicago protester caught on camera admits ...   \n",
      "1     germanys fdp look to fill schaeubles big shoes   \n",
      "2  mi school sends welcome back packet warning ki...   \n",
      "3  un seeks massive aid boost amid rohingya emerg...   \n",
      "4  did oprah just leave nasty hillary wishing she...   \n",
      "\n",
      "                                   preprocessed_text  \\\n",
      "0  wow chicago protester caught on camera admits ...   \n",
      "1     germanys fdp look to fill schaeubles big shoes   \n",
      "2  mi school sends welcome back packet warning ki...   \n",
      "3  un seeks massive aid boost amid rohingya emerg...   \n",
      "4  did oprah just leave nasty hillary wishing she...   \n",
      "\n",
      "                                        no_stopwords  \n",
      "0  wow chicago protester caught camera admits vio...  \n",
      "1        germanys fdp look fill schaeubles big shoes  \n",
      "2  mi school sends welcome back packet warning ki...  \n",
      "3  un seeks massive aid boost amid rohingya emerg...  \n",
      "4  oprah leave nasty hillary wishing wouldnt endo...  \n"
     ]
    }
   ],
   "source": [
    "# Now, replace 2 by either 0 (fake) or 1 (real) using our model\n",
    "# Preprocess the 'title' column in dt using the same steps as training data\n",
    "dt['text_nospecial'] = dt['title'].apply(remove_special_characters)\n",
    "dt['text_nonum'] = dt['text_nospecial'].apply(remove_numbers)\n",
    "dt['text_nosingle'] = dt['text_nonum'].apply(remove_single_characters)\n",
    "dt['text_nosingle_start'] = dt['text_nosingle'].apply(remove_single_characters_start)\n",
    "dt['text_nospaces'] = dt['text_nosingle_start'].apply(substitute_multiple_spaces)\n",
    "dt['text_noprefixb'] = dt['text_nospaces'].apply(remove_prefixed_b)\n",
    "dt['preprocessed_text'] = dt['text_noprefixb'].str.lower()\n",
    "dt['no_stopwords'] = dt['preprocessed_text'].apply(remove_stopwords)\n",
    "\n",
    "# Vectorize using the same vectorizer as training\n",
    "X_dt_bow = vectorizer.transform(dt['no_stopwords'])\n",
    "\n",
    "# Predict labels using the trained model\n",
    "dt_pred = clf.predict(X_dt_bow)\n",
    "\n",
    "# Replace label 2 with predicted values\n",
    "dt.loc[dt['label'] == 2, 'label'] = dt_pred[dt['label'] == 2]\n",
    "\n",
    "print(dt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328a37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
