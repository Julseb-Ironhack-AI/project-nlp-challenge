![alt text](image.png)



ğŸ“° Natural Language Processing Project (Project 2)

Presentation here: [Link to slides]()

ğŸ“Œ  Intro

For this project, our goal was to detect if a news title could be fake or real. We applied Natural Language Processing (NLP) techniques to classify short headlines based on their likelihood of being authentic or misleading.

ğŸ§  Project Overview
This binary classification task is based on a dataset that contains news headlines and a corresponding label:

label:

0 â†’ Fake news

1 â†’ Real news

title: The headline of the article

ğŸ§ª Objective
Build an NLP classifier that can accurately predict whether a headline is fake or real. 

ğŸ§¹ Preprocessing Steps

âœ… Text cleaning: Lowercasing, removing punctuation and special characters

âœ… Tokenization & Lemmatization 

âœ… Stopword Removal

âœ… Train/Test Split: 80% train / 20% test

âœ… TF-IDF vectorization for traditional ML models

âœ… BERT Tokenization for transformer-based models

âœ… Logistic Regression (and others..... )


##### on this I need to check all the model or we can do it together:

ğŸ”§ Modeling Approaches
ğŸ”¹ TF-IDF + Logistic Regression: Accuracy ~94%

ğŸ”¹ BERT + Logistic Regression: Accuracy ~97%

ğŸ”¹ Multinomial_Naive_Bayes 0.9999


ğŸ“Š Evaluation Metrics


Accuracy

F1 Score

Confusion Matrix

ROC-AUC Curve

Model	Accuracy	F1 Score
TF-IDF + Logistic Regression	0.94	0.93
BERT + Logistic Regression	0.97	0.96

0.96

ğŸ”® Predictions
We used our best model (Naive Bayes) to generate predictions on testing_data_lowercase_nolabels.csv, replacing all 2s with either 0 or 1.

ğŸ§¾ Project Structure

ğŸ› ï¸ Requirements
Package	Version

scikit-learn	1.x
pandas	1.x
nltk	latest
matplotlib	latest

ğŸ“ˆ Conclusion
While transformer-based models like BERT demonstrated strong performance, we found that traditional models (e.g., TF-IDF + Logistic Regression) were more suitable for this task. Given the short length of the headlines and the structured nature of the dataset, classical approaches achieved high accuracy (~94%) with significantly faster training and inference times.

For this reason, we preferred the traditional model for deployment â€” it offers a lightweight, efficient, and interpretable solution that still delivers excellent results in real-time through our web app.



